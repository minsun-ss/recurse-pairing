{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfabadb8-5935-45ff-b39c-db7a29012129",
   "metadata": {
    "id": "bfabadb8-5935-45ff-b39c-db7a29012129"
   },
   "source": [
    "# Chapter 6: Finetuning for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "9495f150-9d79-4910-d6e7-6c0d9aae4a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.7\n",
      "numpy version: 2.3.3\n",
      "tiktoken version: 0.12.0\n",
      "torch version: 2.9.0+cu126\n",
      "tensorflow version: 2.20.0\n",
      "pandas version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",  # Plotting library\n",
    "        \"numpy\",       # PyTorch & TensorFlow dependency\n",
    "        \"tiktoken\",    # Tokenizer\n",
    "        \"torch\",       # Deep learning library\n",
    "        \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "        \"pandas\"       # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
    "outputId": "a16c5cde-d341-4887-a93f-baa9bec542ab"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_parquet(\"../clean_dataset/train_clean.parquet\")[[\"summary\", \"nominated\"]].rename(columns={\"summary\": \"Text\", \"nominated\": \"Label\"})\n",
    "test_df = pd.read_parquet(\"../clean_dataset/test_clean.parquet\")[[\"summary\", \"nominated\"]].rename(columns={\"summary\": \"Text\", \"nominated\": \"Label\"})\n",
    "val_df = pd.read_parquet(\"../clean_dataset/val_clean.parquet\")[[\"summary\", \"nominated\"]].rename(columns={\"summary\": \"Text\", \"nominated\": \"Label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc5ce7e9-c32f-4b7f-8dd0-1a69bcc188bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sergeant Nico Toscani, a native of Palermo, Si...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Theodore \"Ted\" Crawford (Anthony Hopkins), a w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In 2017, New York Times reporter Jodi Kantor r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>During an April 1943 bombing mission against t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sherman McCoy is a Wall Street bond trader who...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  Sergeant Nico Toscani, a native of Palermo, Si...      0\n",
       "1  Theodore \"Ted\" Crawford (Anthony Hopkins), a w...      0\n",
       "2  In 2017, New York Times reporter Jodi Kantor r...      0\n",
       "3  During an April 1943 bombing mission against t...      0\n",
       "4  Sherman McCoy is a Wall Street bond trader who...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
    "outputId": "761e0482-43ba-4f46-f4b7-6774dae51b38"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)\n",
    "val_df.to_csv(\"validation.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
    "outputId": "b5b48439-32c8-4b37-cca2-c9dc8fa86563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7791b52-af18-4ac4-afa9-b921068e383e",
   "metadata": {
    "id": "d7791b52-af18-4ac4-afa9-b921068e383e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            # self.encoded_texts = [\n",
    "            #     encoded_text[:self.max_length]\n",
    "            #     for encoded_text in self.encoded_texts\n",
    "            # ]\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[-self.max_length:]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n",
    "        # Note: A more pythonic version to implement this method\n",
    "        # is the following, which is also used in the next chapter:\n",
    "        # return max(len(encoded_text) for encoded_text in self.encoded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "uzj85f8ou82h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzj85f8ou82h",
    "outputId": "d08f1cf0-c24d-445f-a3f8-793532c3716f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MovieDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=1024,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "016a44a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e",
   "metadata": {
    "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e"
   },
   "outputs": [],
   "source": [
    "val_dataset = MovieDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = MovieDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
    "outputId": "3266c410-4fdb-4a8c-a142-7f707e2525ab"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 1024])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "6934bbf2-9797-4fbe-d26b-1a246e18c2fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 training batches\n",
      "55 validation batches\n",
      "55 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9f9ad66-4969-4501-8239-3ccdb37e71a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class OscarPredictor(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=256, nhead=8, num_encoder_layers=4, num_decoder_layers=2):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_emb = nn.Parameter(torch.zeros(1, 1024, d_model))  # positional embedding\n",
    "        \n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True),\n",
    "            num_layers=num_encoder_layers,\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, batch_first=True),\n",
    "            num_layers=num_decoder_layers,\n",
    "        )\n",
    "        \n",
    "        # A learnable query for the decoder to attend to the encoder outputs\n",
    "        self.query = nn.Parameter(torch.randn(1, 1, d_model))\n",
    "        \n",
    "        # Final classifier\n",
    "        self.fc = nn.Linear(d_model, 1)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        # input_ids: [B, T]\n",
    "        x = self.token_emb(input_ids) + self.pos_emb[:, :input_ids.size(1), :]\n",
    "        memory = self.encoder(x, src_key_padding_mask=(attention_mask == 0) if attention_mask is not None else None)\n",
    "        \n",
    "        # Use the same query for all batches\n",
    "        query = self.query.expand(input_ids.size(0), -1, -1)\n",
    "        \n",
    "        # The decoder attends to the encoder memory\n",
    "        out = self.decoder(query, memory)\n",
    "        \n",
    "        # Predict a single probability\n",
    "        logits = self.fc(out.squeeze(1))  # shape [B, 1]\n",
    "        # prob = torch.sigmoid(logits)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e22a081",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "# assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "#     f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "#     f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "#     f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32975582",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OscarPredictor(vocab_size=BASE_CONFIG['vocab_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Training accuracy: 83.75%\n",
      "Validation accuracy: 82.50%\n",
      "Test accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # Use PyTorch 2.9 or newer for stable mps results\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e121268e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.811\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming:\n",
    "#   - model: your trained OscarPredictor\n",
    "#   - test_loader: a DataLoader yielding (input_ids, attention_mask, labels)\n",
    "\n",
    "def evaluate_and_plot_confusion(model, test_loader, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids, labels = batch\n",
    "\n",
    "            input_ids = input_ids.to(device)\n",
    "\n",
    "            probs = model(input_ids)\n",
    "            preds = (probs > 0.5).long().cpu().numpy()   # threshold at 0.5\n",
    "\n",
    "            all_preds.extend(preds.flatten())\n",
    "            all_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=[0, 1])\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Oscar Nom\", \"Oscar Nom\"])\n",
    "    disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "\n",
    "    plt.title(\"Confusion Matrix  Oscar Prediction\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Optional: return metrics\n",
    "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "    return cm, accuracy\n",
    "\n",
    "\n",
    "# Example usage\n",
    "cm, acc = evaluate_and_plot_confusion(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4",
   "metadata": {
    "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013aab9-f854-4866-ad55-5b8350adb50a",
   "metadata": {},
   "source": [
    "The `calc_loss_loader` is exactly the same as in chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b83e10-5720-45e7-ac5e-369417ca846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in chapter 5\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56826ecd-6e74-40e6-b772-d3541e585067",
   "metadata": {},
   "source": [
    "- Using the `calc_closs_loader`, we compute the initial training, validation, and test set losses before we start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
    "outputId": "49df8648-9e38-4314-854d-9faacd1b2e89"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Csbr60to50FL",
   "metadata": {
    "id": "Csbr60to50FL"
   },
   "outputs": [],
   "source": [
    "# Overall the same as `train_model_simple` in chapter 5\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X7kU3aAj7vTJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7kU3aAj7vTJ",
    "outputId": "504a033e-2bf8-41b5-a037-468309845513"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cURgnDqdCeka",
   "metadata": {
    "id": "cURgnDqdCeka"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OIqRt466DiGk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "OIqRt466DiGk",
    "outputId": "b16987cf-0001-4652-ddaf-02f7cffc34db"
   },
   "outputs": [],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yz8BIsaF0TUo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "yz8BIsaF0TUo",
    "outputId": "3a7ed967-1f2a-4c6d-f4a3-0cc8cc9d6c5f"
   },
   "outputs": [],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UHWaJFrjY0zW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHWaJFrjY0zW",
    "outputId": "e111e6e6-b147-4159-eb9d-19d4e809ed34"
   },
   "outputs": [],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31",
   "metadata": {},
   "source": [
    "- Finally, let's use the finetuned GPT model in action\n",
    "- The `classify_review` function below implements the data preprocessing steps similar to the `SpamDataset` we implemented earlier\n",
    "- Then, the function returns the predicted integer class label from the model and returns the corresponding class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aHdn6xvL-IW5",
   "metadata": {
    "id": "aHdn6xvL-IW5"
   },
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "    assert max_length is not None, (\n",
    "        \"max_length must be specified. If you want to use the full model context, \"\n",
    "        \"pass max_length=model.pos_emb.weight.shape[0].\"\n",
    "    )\n",
    "    assert max_length <= supported_context_length, (\n",
    "        f\"max_length ({max_length}) exceeds model's supported context length ({supported_context_length}).\"\n",
    "    )    \n",
    "    # Alternatively, a more robust version is the following one, which handles the max_length=None case better\n",
    "    # max_len = min(max_length,supported_context_length) if max_length else supported_context_length\n",
    "    # input_ids = input_ids[:max_len]\n",
    "    \n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c",
   "metadata": {},
   "source": [
    "- Let's try it out on a few examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apU_pf51AWSV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apU_pf51AWSV",
    "outputId": "d0fde0a5-e7a3-4dbe-d9c5-0567dbab7e62"
   },
   "outputs": [],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1g5VTOo_Ajs5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1g5VTOo_Ajs5",
    "outputId": "659b08eb-b6a9-4a8a-9af7-d94c757e93c2"
   },
   "outputs": [],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e",
   "metadata": {},
   "source": [
    "- Finally, let's save the model in case we want to reuse the model later without having to train it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mYnX-gI1CfQY",
   "metadata": {
    "id": "mYnX-gI1CfQY"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6",
   "metadata": {},
   "source": [
    "- Then, in a new session, we could load the model as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4",
   "metadata": {
    "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4"
   },
   "source": [
    "## Summary and takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e",
   "metadata": {},
   "source": [
    "- See the [./gpt_class_finetune.py](./gpt_class_finetune.py) script, a self-contained script for classification finetuning\n",
    "- You can find the exercise solutions in [./exercise-solutions.ipynb](./exercise-solutions.ipynb)\n",
    "- In addition, interested readers can find an introduction to parameter-efficient training with low-rank adaptation (LoRA) in [appendix E](../../appendix-E)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "learn-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
